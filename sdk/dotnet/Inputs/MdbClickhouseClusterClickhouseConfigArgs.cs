// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Yandex.Inputs
{

    public sealed class MdbClickhouseClusterClickhouseConfigArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Enable or disable asynchronous_insert_log system table.
        /// </summary>
        [Input("asynchronousInsertLogEnabled")]
        public Input<bool>? AsynchronousInsertLogEnabled { get; set; }

        /// <summary>
        /// The maximum size that asynchronous_insert_log can grow to before old data will be removed.
        /// </summary>
        [Input("asynchronousInsertLogRetentionSize")]
        public Input<int>? AsynchronousInsertLogRetentionSize { get; set; }

        /// <summary>
        /// The maximum time that asynchronous_insert_log records will be retained before removal.
        /// </summary>
        [Input("asynchronousInsertLogRetentionTime")]
        public Input<int>? AsynchronousInsertLogRetentionTime { get; set; }

        /// <summary>
        /// Enable or disable asynchronous_metric_log system table.
        /// </summary>
        [Input("asynchronousMetricLogEnabled")]
        public Input<bool>? AsynchronousMetricLogEnabled { get; set; }

        /// <summary>
        /// The maximum size that asynchronous_metric_log can grow to before old data will be removed.
        /// </summary>
        [Input("asynchronousMetricLogRetentionSize")]
        public Input<int>? AsynchronousMetricLogRetentionSize { get; set; }

        /// <summary>
        /// The maximum time that asynchronous_metric_log records will be retained before removal.
        /// </summary>
        [Input("asynchronousMetricLogRetentionTime")]
        public Input<int>? AsynchronousMetricLogRetentionTime { get; set; }

        /// <summary>
        /// The maximum number of threads that will be used for performing flush operations for Buffer-engine tables in the background.
        /// </summary>
        [Input("backgroundBufferFlushSchedulePoolSize")]
        public Input<int>? BackgroundBufferFlushSchedulePoolSize { get; set; }

        /// <summary>
        /// The maximum number of threads that will be used for performing a variety of operations (mostly garbage collection) for MergeTree-engine tables in a background.
        /// </summary>
        [Input("backgroundCommonPoolSize")]
        public Input<int>? BackgroundCommonPoolSize { get; set; }

        /// <summary>
        /// The maximum number of threads that will be used for executing distributed sends.
        /// </summary>
        [Input("backgroundDistributedSchedulePoolSize")]
        public Input<int>? BackgroundDistributedSchedulePoolSize { get; set; }

        /// <summary>
        /// The maximum number of threads that will be used for fetching data parts from another replica for MergeTree-engine tables in a background.
        /// </summary>
        [Input("backgroundFetchesPoolSize")]
        public Input<int>? BackgroundFetchesPoolSize { get; set; }

        /// <summary>
        /// Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently.
        /// </summary>
        [Input("backgroundMergesMutationsConcurrencyRatio")]
        public Input<int>? BackgroundMergesMutationsConcurrencyRatio { get; set; }

        /// <summary>
        /// The maximum number of threads that will be used for executing background operations for message streaming.
        /// </summary>
        [Input("backgroundMessageBrokerSchedulePoolSize")]
        public Input<int>? BackgroundMessageBrokerSchedulePoolSize { get; set; }

        /// <summary>
        /// The maximum number of threads that will be used for moving data parts to another disk or volume for MergeTree-engine tables in a background.
        /// </summary>
        [Input("backgroundMovePoolSize")]
        public Input<int>? BackgroundMovePoolSize { get; set; }

        /// <summary>
        /// Sets the number of threads performing background merges and mutations for MergeTree-engine tables.
        /// </summary>
        [Input("backgroundPoolSize")]
        public Input<int>? BackgroundPoolSize { get; set; }

        /// <summary>
        /// The maximum number of threads that will be used for constantly executing some lightweight periodic operations for replicated tables, Kafka streaming, and DNS cache updates.
        /// </summary>
        [Input("backgroundSchedulePoolSize")]
        public Input<int>? BackgroundSchedulePoolSize { get; set; }

        [Input("compressions")]
        private InputList<Inputs.MdbClickhouseClusterClickhouseConfigCompressionArgs>? _compressions;

        /// <summary>
        /// Data compression configuration.
        /// </summary>
        public InputList<Inputs.MdbClickhouseClusterClickhouseConfigCompressionArgs> Compressions
        {
            get => _compressions ?? (_compressions = new InputList<Inputs.MdbClickhouseClusterClickhouseConfigCompressionArgs>());
            set => _compressions = value;
        }

        /// <summary>
        /// Default database name.
        /// </summary>
        [Input("defaultDatabase")]
        public Input<string>? DefaultDatabase { get; set; }

        /// <summary>
        /// Lazy loading of dictionaries. If true, then each dictionary is loaded on the first use.
        /// </summary>
        [Input("dictionariesLazyLoad")]
        public Input<bool>? DictionariesLazyLoad { get; set; }

        /// <summary>
        /// Enable or disable geobase.
        /// </summary>
        [Input("geobaseEnabled")]
        public Input<bool>? GeobaseEnabled { get; set; }

        /// <summary>
        /// Address of the archive with the user geobase in Object Storage.
        /// </summary>
        [Input("geobaseUri")]
        public Input<string>? GeobaseUri { get; set; }

        [Input("graphiteRollups")]
        private InputList<Inputs.MdbClickhouseClusterClickhouseConfigGraphiteRollupArgs>? _graphiteRollups;

        /// <summary>
        /// Graphite rollup configuration.
        /// </summary>
        public InputList<Inputs.MdbClickhouseClusterClickhouseConfigGraphiteRollupArgs> GraphiteRollups
        {
            get => _graphiteRollups ?? (_graphiteRollups = new InputList<Inputs.MdbClickhouseClusterClickhouseConfigGraphiteRollupArgs>());
            set => _graphiteRollups = value;
        }

        /// <summary>
        /// JDBC bridge configuration.
        /// </summary>
        [Input("jdbcBridge")]
        public Input<Inputs.MdbClickhouseClusterClickhouseConfigJdbcBridgeArgs>? JdbcBridge { get; set; }

        /// <summary>
        /// Kafka connection configuration.
        /// </summary>
        [Input("kafka")]
        public Input<Inputs.MdbClickhouseClusterClickhouseConfigKafkaArgs>? Kafka { get; set; }

        [Input("kafkaTopics")]
        private InputList<Inputs.MdbClickhouseClusterClickhouseConfigKafkaTopicArgs>? _kafkaTopics;

        /// <summary>
        /// Kafka topic connection configuration.
        /// </summary>
        public InputList<Inputs.MdbClickhouseClusterClickhouseConfigKafkaTopicArgs> KafkaTopics
        {
            get => _kafkaTopics ?? (_kafkaTopics = new InputList<Inputs.MdbClickhouseClusterClickhouseConfigKafkaTopicArgs>());
            set => _kafkaTopics = value;
        }

        /// <summary>
        /// The number of seconds that ClickHouse waits for incoming requests for HTTP protocol before closing the connection.
        /// </summary>
        [Input("keepAliveTimeout")]
        public Input<int>? KeepAliveTimeout { get; set; }

        /// <summary>
        /// Logging level.
        /// </summary>
        [Input("logLevel")]
        public Input<string>? LogLevel { get; set; }

        /// <summary>
        /// Maximum size of cache for marks
        /// </summary>
        [Input("markCacheSize")]
        public Input<int>? MarkCacheSize { get; set; }

        /// <summary>
        /// Limit on total number of concurrently executed queries.
        /// </summary>
        [Input("maxConcurrentQueries")]
        public Input<int>? MaxConcurrentQueries { get; set; }

        /// <summary>
        /// Max server connections.
        /// </summary>
        [Input("maxConnections")]
        public Input<int>? MaxConnections { get; set; }

        /// <summary>
        /// Restriction on dropping partitions.
        /// </summary>
        [Input("maxPartitionSizeToDrop")]
        public Input<int>? MaxPartitionSizeToDrop { get; set; }

        /// <summary>
        /// Restriction on deleting tables.
        /// </summary>
        [Input("maxTableSizeToDrop")]
        public Input<int>? MaxTableSizeToDrop { get; set; }

        /// <summary>
        /// MergeTree engine configuration.
        /// </summary>
        [Input("mergeTree")]
        public Input<Inputs.MdbClickhouseClusterClickhouseConfigMergeTreeArgs>? MergeTree { get; set; }

        /// <summary>
        /// Enable or disable metric_log system table.
        /// </summary>
        [Input("metricLogEnabled")]
        public Input<bool>? MetricLogEnabled { get; set; }

        /// <summary>
        /// The maximum size that metric_log can grow to before old data will be removed.
        /// </summary>
        [Input("metricLogRetentionSize")]
        public Input<int>? MetricLogRetentionSize { get; set; }

        /// <summary>
        /// The maximum time that metric_log records will be retained before removal.
        /// </summary>
        [Input("metricLogRetentionTime")]
        public Input<int>? MetricLogRetentionTime { get; set; }

        /// <summary>
        /// Enable or disable opentelemetry_span_log system table.
        /// </summary>
        [Input("opentelemetrySpanLogEnabled")]
        public Input<bool>? OpentelemetrySpanLogEnabled { get; set; }

        /// <summary>
        /// The maximum size that opentelemetry_span_log can grow to before old data will be removed.
        /// </summary>
        [Input("opentelemetrySpanLogRetentionSize")]
        public Input<int>? OpentelemetrySpanLogRetentionSize { get; set; }

        /// <summary>
        /// The maximum time that opentelemetry_span_log records will be retained before removal.
        /// </summary>
        [Input("opentelemetrySpanLogRetentionTime")]
        public Input<int>? OpentelemetrySpanLogRetentionTime { get; set; }

        /// <summary>
        /// The maximum size that part_log can grow to before old data will be removed.
        /// </summary>
        [Input("partLogRetentionSize")]
        public Input<int>? PartLogRetentionSize { get; set; }

        /// <summary>
        /// The maximum time that part_log records will be retained before removal.
        /// </summary>
        [Input("partLogRetentionTime")]
        public Input<int>? PartLogRetentionTime { get; set; }

        /// <summary>
        /// Query cache configuration.
        /// </summary>
        [Input("queryCache")]
        public Input<Inputs.MdbClickhouseClusterClickhouseConfigQueryCacheArgs>? QueryCache { get; set; }

        /// <summary>
        /// The maximum size that query_log can grow to before old data will be removed.
        /// </summary>
        [Input("queryLogRetentionSize")]
        public Input<int>? QueryLogRetentionSize { get; set; }

        /// <summary>
        /// The maximum time that query_log records will be retained before removal.
        /// </summary>
        [Input("queryLogRetentionTime")]
        public Input<int>? QueryLogRetentionTime { get; set; }

        [Input("queryMaskingRules")]
        private InputList<Inputs.MdbClickhouseClusterClickhouseConfigQueryMaskingRuleArgs>? _queryMaskingRules;

        /// <summary>
        /// Query masking rules configuration.
        /// </summary>
        public InputList<Inputs.MdbClickhouseClusterClickhouseConfigQueryMaskingRuleArgs> QueryMaskingRules
        {
            get => _queryMaskingRules ?? (_queryMaskingRules = new InputList<Inputs.MdbClickhouseClusterClickhouseConfigQueryMaskingRuleArgs>());
            set => _queryMaskingRules = value;
        }

        /// <summary>
        /// Enable or disable query_thread_log system table.
        /// </summary>
        [Input("queryThreadLogEnabled")]
        public Input<bool>? QueryThreadLogEnabled { get; set; }

        /// <summary>
        /// The maximum size that query_thread_log can grow to before old data will be removed.
        /// </summary>
        [Input("queryThreadLogRetentionSize")]
        public Input<int>? QueryThreadLogRetentionSize { get; set; }

        /// <summary>
        /// The maximum time that query_thread_log records will be retained before removal.
        /// </summary>
        [Input("queryThreadLogRetentionTime")]
        public Input<int>? QueryThreadLogRetentionTime { get; set; }

        /// <summary>
        /// Enable or disable query_views_log system table.
        /// </summary>
        [Input("queryViewsLogEnabled")]
        public Input<bool>? QueryViewsLogEnabled { get; set; }

        /// <summary>
        /// The maximum size that query_views_log can grow to before old data will be removed.
        /// </summary>
        [Input("queryViewsLogRetentionSize")]
        public Input<int>? QueryViewsLogRetentionSize { get; set; }

        /// <summary>
        /// The maximum time that query_views_log records will be retained before removal.
        /// </summary>
        [Input("queryViewsLogRetentionTime")]
        public Input<int>? QueryViewsLogRetentionTime { get; set; }

        /// <summary>
        /// RabbitMQ connection configuration.
        /// </summary>
        [Input("rabbitmq")]
        public Input<Inputs.MdbClickhouseClusterClickhouseConfigRabbitmqArgs>? Rabbitmq { get; set; }

        /// <summary>
        /// Enable or disable session_log system table.
        /// </summary>
        [Input("sessionLogEnabled")]
        public Input<bool>? SessionLogEnabled { get; set; }

        /// <summary>
        /// The maximum size that session_log can grow to before old data will be removed.
        /// </summary>
        [Input("sessionLogRetentionSize")]
        public Input<int>? SessionLogRetentionSize { get; set; }

        /// <summary>
        /// The maximum time that session_log records will be retained before removal.
        /// </summary>
        [Input("sessionLogRetentionTime")]
        public Input<int>? SessionLogRetentionTime { get; set; }

        /// <summary>
        /// Enable or disable text_log system table.
        /// </summary>
        [Input("textLogEnabled")]
        public Input<bool>? TextLogEnabled { get; set; }

        /// <summary>
        /// Logging level for text_log system table.
        /// </summary>
        [Input("textLogLevel")]
        public Input<string>? TextLogLevel { get; set; }

        /// <summary>
        /// The maximum size that text_log can grow to before old data will be removed.
        /// </summary>
        [Input("textLogRetentionSize")]
        public Input<int>? TextLogRetentionSize { get; set; }

        /// <summary>
        /// The maximum time that text_log records will be retained before removal.
        /// </summary>
        [Input("textLogRetentionTime")]
        public Input<int>? TextLogRetentionTime { get; set; }

        /// <summary>
        /// The server's time zone.
        /// </summary>
        [Input("timezone")]
        public Input<string>? Timezone { get; set; }

        /// <summary>
        /// Whenever server memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stack trace.
        /// </summary>
        [Input("totalMemoryProfilerStep")]
        public Input<int>? TotalMemoryProfilerStep { get; set; }

        /// <summary>
        /// Enable or disable trace_log system table.
        /// </summary>
        [Input("traceLogEnabled")]
        public Input<bool>? TraceLogEnabled { get; set; }

        /// <summary>
        /// The maximum size that trace_log can grow to before old data will be removed.
        /// </summary>
        [Input("traceLogRetentionSize")]
        public Input<int>? TraceLogRetentionSize { get; set; }

        /// <summary>
        /// The maximum time that trace_log records will be retained before removal.
        /// </summary>
        [Input("traceLogRetentionTime")]
        public Input<int>? TraceLogRetentionTime { get; set; }

        /// <summary>
        /// Cache size (in bytes) for uncompressed data used by table engines from the MergeTree family. Zero means disabled.
        /// </summary>
        [Input("uncompressedCacheSize")]
        public Input<int>? UncompressedCacheSize { get; set; }

        /// <summary>
        /// Enable or disable zookeeper_log system table.
        /// </summary>
        [Input("zookeeperLogEnabled")]
        public Input<bool>? ZookeeperLogEnabled { get; set; }

        /// <summary>
        /// The maximum size that zookeeper_log can grow to before old data will be removed.
        /// </summary>
        [Input("zookeeperLogRetentionSize")]
        public Input<int>? ZookeeperLogRetentionSize { get; set; }

        /// <summary>
        /// The maximum time that zookeeper_log records will be retained before removal.
        /// </summary>
        [Input("zookeeperLogRetentionTime")]
        public Input<int>? ZookeeperLogRetentionTime { get; set; }

        public MdbClickhouseClusterClickhouseConfigArgs()
        {
        }
        public static new MdbClickhouseClusterClickhouseConfigArgs Empty => new MdbClickhouseClusterClickhouseConfigArgs();
    }
}
