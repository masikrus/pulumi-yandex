// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Yandex.Inputs
{

    public sealed class MdbKafkaClusterTopicTopicConfigArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Retention policy to use on log segments.
        /// </summary>
        [Input("cleanupPolicy")]
        public Input<string>? CleanupPolicy { get; set; }

        /// <summary>
        /// Compression type of kafka topic.
        /// </summary>
        [Input("compressionType")]
        public Input<string>? CompressionType { get; set; }

        /// <summary>
        /// The amount of time to retain delete tombstone markers for log compacted topics.
        /// </summary>
        [Input("deleteRetentionMs")]
        public Input<string>? DeleteRetentionMs { get; set; }

        /// <summary>
        /// The time to wait before deleting a file from the filesystem.
        /// </summary>
        [Input("fileDeleteDelayMs")]
        public Input<string>? FileDeleteDelayMs { get; set; }

        /// <summary>
        /// This setting allows specifying an interval at which we will force an fsync of data written to the log.
        /// </summary>
        [Input("flushMessages")]
        public Input<string>? FlushMessages { get; set; }

        /// <summary>
        /// This setting allows specifying a time interval at which we will force an fsync of data written to the log.
        /// </summary>
        [Input("flushMs")]
        public Input<string>? FlushMs { get; set; }

        /// <summary>
        /// The largest record batch size allowed by Kafka (after compression if compression is enabled).
        /// </summary>
        [Input("maxMessageBytes")]
        public Input<string>? MaxMessageBytes { get; set; }

        /// <summary>
        /// The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.
        /// </summary>
        [Input("minCompactionLagMs")]
        public Input<string>? MinCompactionLagMs { get; set; }

        /// <summary>
        /// When a producer sets acks to "all" (or "-1"), this configuration specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful.
        /// </summary>
        [Input("minInsyncReplicas")]
        public Input<string>? MinInsyncReplicas { get; set; }

        /// <summary>
        /// True if we should preallocate the file on disk when creating a new log segment.
        /// </summary>
        [Input("preallocate")]
        public Input<bool>? Preallocate { get; set; }

        /// <summary>
        /// This configuration controls the maximum size a partition (which consists of log segments) can grow to before we will discard old log segments to free up space if we are using the "delete" retention policy.
        /// </summary>
        [Input("retentionBytes")]
        public Input<string>? RetentionBytes { get; set; }

        /// <summary>
        /// This configuration controls the maximum time we will retain a log before we will discard old log segments to free up space if we are using the "delete" retention policy.
        /// </summary>
        [Input("retentionMs")]
        public Input<string>? RetentionMs { get; set; }

        /// <summary>
        /// This configuration controls the segment file size for the log.
        /// </summary>
        [Input("segmentBytes")]
        public Input<string>? SegmentBytes { get; set; }

        public MdbKafkaClusterTopicTopicConfigArgs()
        {
        }
        public static new MdbKafkaClusterTopicTopicConfigArgs Empty => new MdbKafkaClusterTopicTopicConfigArgs();
    }
}
